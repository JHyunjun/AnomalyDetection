{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/AnomalyDetection/blob/main/240824_1DCNN_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2dJqWlTSCJJ3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SU0tC8S3CJJ5"
      },
      "outputs": [],
      "source": [
        "# # TensorFlow 버전 출력\n",
        "# print(\"TensorFlow 버전:\", tf.__version__)\n",
        "\n",
        "# # 사용 가능한 GPU 목록 확인\n",
        "# gpus = tf.config.list_physical_devices('GPU')\n",
        "# print(\"사용 가능한 GPU:\", gpus)\n",
        "\n",
        "# if gpus:\n",
        "#     # GPU가 감지되면 간단한 연산 수행\n",
        "#     with tf.device('/GPU:0'):\n",
        "#         a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "#         b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "#         c = tf.matmul(a, b)\n",
        "#         print(\"GPU에서 수행된 행렬 곱셈 결과:\")\n",
        "#         print(c)\n",
        "# else:\n",
        "#     print(\"GPU를 찾을 수 없습니다. CPU에서 실행됩니다.\")\n",
        "\n",
        "# # 현재 사용 중인 장치 확인\n",
        "# print(\"현재 사용 중인 장치:\", tf.test.gpu_device_name())\n",
        "\n",
        "# # GPU 사용 가능 여부 확인\n",
        "# print(\"GPU 사용 가능:\", tf.test.is_built_with_cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bxl5kf3CJJ6",
        "outputId": "358342bb-ee32-486a-ab6b-8edf28b1dabf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data points: 496800\n",
            "Number of anomalies: 0\n",
            "Anomaly ratio: 0.00%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터 로드\n",
        "TRAIN_DF_RAW = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/AutoEncoder/AnomalyDetection_2408_Dayconb/train.csv\")\n",
        "TEST_DF_RAW = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/AutoEncoder/AnomalyDetection_2408_Dayconb/test.csv\")\n",
        "\n",
        "COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop([\"Timestamp\", 'anomaly'])\n",
        "\n",
        "# TIME_STEP 열 추가 (0부터 시작하는 인덱스)\n",
        "TRAIN_DF_RAW['TIME_STEP'] = range(len(TRAIN_DF_RAW))\n",
        "\n",
        "# # 그래프 그리기\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.scatter(TRAIN_DF_RAW['TIME_STEP'], TRAIN_DF_RAW['anomaly'], alpha=0.5)\n",
        "\n",
        "# plt.title('Anomaly Detection Over Time Steps', fontsize=20)\n",
        "# plt.xlabel('TIME_STEP', fontsize=14)\n",
        "# plt.ylabel('Anomaly', fontsize=14)\n",
        "# plt.yticks([0, 1])\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# 통계 정보 출력\n",
        "anomaly_count = TRAIN_DF_RAW['anomaly'].sum()\n",
        "total_count = len(TRAIN_DF_RAW)\n",
        "print(f\"Total data points: {total_count}\")\n",
        "print(f\"Number of anomalies: {anomaly_count}\")\n",
        "print(f\"Anomaly ratio: {anomaly_count/total_count*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s1qu71rCJJ6",
        "outputId": "c1655d2a-8d56-48c6-e864-92b664836b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN_DF.shape :  (496800, 51)\n",
            "TEST_DF.shape :  (450000, 51)\n"
          ]
        }
      ],
      "source": [
        "# 정규화 과정\n",
        "TRN_MIN = TRAIN_DF_RAW[COLUMNS_IN_TRAIN_DATASET].min()\n",
        "TRN_MAX = TRAIN_DF_RAW[COLUMNS_IN_TRAIN_DATASET].max()\n",
        "\n",
        "def normalize(df):\n",
        "    ndf = df.copy()\n",
        "    for c in df.columns:\n",
        "        if TRN_MAX[c] != TRN_MIN[c]:\n",
        "            ndf[c] = (df[c] - TRN_MIN[c]) / (TRN_MAX[c] - TRN_MIN[c])\n",
        "    return ndf\n",
        "\n",
        "TRAIN_DF = normalize(TRAIN_DF_RAW[COLUMNS_IN_TRAIN_DATASET])\n",
        "TEST_DF = normalize(TEST_DF_RAW[COLUMNS_IN_TRAIN_DATASET])\n",
        "\n",
        "print(\"TRAIN_DF.shape : \", TRAIN_DF.shape)\n",
        "print(\"TEST_DF.shape : \", TEST_DF.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HxVpIrcCJJ7",
        "outputId": "881633d6-cb70-426a-f9e6-3e52649f248e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original TRAIN_DF shape: (496800, 51)\n",
            "After windowing, train_windows shape: (496791, 10, 51)\n",
            "\n",
            "Original TEST_DF shape: (450000, 51)\n",
            "After windowing, test_windows shape: (449991, 10, 51)\n"
          ]
        }
      ],
      "source": [
        "def create_windows(data, window_size):\n",
        "    windows = []\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        windows.append(data[i:i+window_size])\n",
        "    return np.array(windows)\n",
        "\n",
        "# TRAIN_DF를 윈도우로 나누기\n",
        "window_size = 10\n",
        "train_windows = create_windows(TRAIN_DF.values, window_size)\n",
        "\n",
        "print(\"Original TRAIN_DF shape:\", TRAIN_DF.shape)\n",
        "print(\"After windowing, train_windows shape:\", train_windows.shape)\n",
        "\n",
        "# TEST_DF도 같은 방식으로 윈도우로 나누기\n",
        "test_windows = create_windows(TEST_DF.values, window_size)\n",
        "\n",
        "print(\"\\nOriginal TEST_DF shape:\", TEST_DF.shape)\n",
        "print(\"After windowing, test_windows shape:\", test_windows.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fvPhoN8nCJJ7"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "train_windows = create_windows(TRAIN_DF.values, window_size)\n",
        "test_windows = create_windows(TEST_DF.values, window_size)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "train_windows_flat = train_windows.reshape(-1, train_windows.shape[-1])\n",
        "train_windows_scaled = scaler.fit_transform(train_windows_flat).reshape(train_windows.shape)\n",
        "test_windows_scaled = scaler.transform(test_windows.reshape(-1, test_windows.shape[-1])).reshape(test_windows.shape)\n",
        "\n",
        "# 학습 데이터와 검증 데이터 분리\n",
        "train_data, val_data = train_test_split(train_windows_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1D-CNN Autoencoder 모델 정의 (수정됨)\n",
        "def create_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(2, padding='same'),\n",
        "        layers.Conv1D(16, 3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(8, 3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(16, 3, activation='relu', padding='same'),\n",
        "        layers.UpSampling1D(2),\n",
        "        layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
        "        layers.Conv1D(input_shape[-1], 3, activation=None, padding='same')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 모델 생성 및 컴파일\n",
        "model = create_model(train_data.shape[1:])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_data, train_data,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_data=(val_data, val_data),\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 재구성 오차 계산\n",
        "train_pred = model.predict(train_windows_scaled)\n",
        "train_mse = np.mean(np.square(train_windows_scaled - train_pred), axis=(1,2))\n",
        "\n",
        "# 이상치 탐지를 위한 임계값 설정 (예: 99 퍼센타일)\n",
        "threshold = np.percentile(train_mse, 99)\n",
        "\n",
        "# 테스트 데이터에 대한 예측 및 이상 탐지\n",
        "test_pred = model.predict(test_windows_scaled)\n",
        "test_mse = np.mean(np.square(test_windows_scaled - test_pred), axis=(1,2))\n",
        "anomalies = test_mse > threshold\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Detected anomalies: {np.sum(anomalies)}\")\n",
        "print(f\"Anomaly ratio: {np.mean(anomalies)*100:.2f}%\")\n",
        "\n",
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_mse, label='Reconstruction Error')\n",
        "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
        "plt.title('Anomaly Detection Results')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Reconstruction Error')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1nxvIuwcDi7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}